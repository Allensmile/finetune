

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Finetune Quickstart Guide &mdash; finetune 0.1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="finetune 0.1.0 documentation" href="#"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="#" class="icon icon-home"> finetune
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Finetune Quickstart Guide</a></li>
<li><a class="reference internal" href="#installation">Installation</a></li>
<li><a class="reference internal" href="#docker">Docker</a></li>
<li><a class="reference internal" href="#code-examples">Code Examples</a></li>
<li><a class="reference internal" href="#finetune-api-reference">Finetune API Reference</a></li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">finetune</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Finetune Quickstart Guide</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="figure">
<img alt="https://i.imgur.com/kYL058E.png" src="https://i.imgur.com/kYL058E.png" />
</div>
<span class="target" id="module-finetune"></span><p><strong>Scikit-learn inspired model finetuning for natural language processing.</strong></p>
<p><a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finetune</span></code></a> ships with a pre-trained language model from <a class="reference external" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">“Improving Language Understanding by Generative Pre-Training”</a>
and builds off the <a class="reference external" href="https://github.com/openai/finetune-transformer-lm">OpenAI/finetune-language-model repository</a>.</p>
<p>Source code for <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finetune</span></code></a> is available <a class="reference external" href="https://github.com/IndicoDataSolutions/finetune">on github</a>.</p>
<div class="section" id="finetune-quickstart-guide">
<h1>Finetune Quickstart Guide<a class="headerlink" href="#finetune-quickstart-guide" title="Permalink to this headline">¶</a></h1>
<p>Finetuning the base language model is as easy as calling <a class="reference internal" href="#finetune.Classifier.fit" title="finetune.Classifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Classifier.fit()</span></code></a>:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">()</span>               <span class="c1"># Load base model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">)</span>          <span class="c1"># Finetune base model on custom data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span> <span class="c1"># [{&#39;class_1&#39;: 0.23, &#39;class_2&#39;: 0.54, ..}, ..]</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>                   <span class="c1"># Serialize the model to disk</span>
</pre></div>
</div>
<p>Reload saved models from disk by using <a class="reference internal" href="#finetune.Classifier.load" title="finetune.Classifier.load"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Classifier.load()</span></code></a>:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Classifier</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>Finetune can be installed directly from PyPI by using <cite>pip</cite></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install finetune
</pre></div>
</div>
<p>or installed directly from source:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/IndicoDataSolutions/finetune
<span class="nb">cd</span> finetune
python3 setup.py develop
python3 -m spacy download en
</pre></div>
</div>
<p>You can optionally run the provided test suite to ensure installation completed successfully.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip3 install pytest
pytest
</pre></div>
</div>
</div>
<div class="section" id="docker">
<h1>Docker<a class="headerlink" href="#docker" title="Permalink to this headline">¶</a></h1>
<p>If you’d prefer you can also run <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-mod docutils literal notranslate"><span class="pre">finetune</span></code></a> in a docker container. The bash scripts provided assume you have a functional install of <a class="reference external" href="https://docs.docker.com/install">docker</a> and <a class="reference external" href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)">nvidia-docker</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./docker/build_docker.sh      <span class="c1"># builds a docker image</span>
./docker/start_docker.sh      <span class="c1"># starts a docker container in the background</span>
docker <span class="nb">exec</span> -it finetune bash <span class="c1"># starts a bash session in the docker container</span>
</pre></div>
</div>
</div>
<div class="section" id="code-examples">
<h1>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h1>
<p>For example usage of provided models, see the <a class="reference external" href="https://github.com/IndicoDataSolutions/finetune/tree/master/finetune/datasets">finetune/datasets directory</a>.</p>
</div>
<div class="section" id="finetune-api-reference">
<h1>Finetune API Reference<a class="headerlink" href="#finetune-api-reference" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="finetune.Classifier">
<em class="property">class </em><code class="descclassname">finetune.</code><code class="descname">Classifier</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="finetune.Classifier.featurize">
<code class="descname">featurize</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.featurize" title="Permalink to this definition">¶</a></dt>
<dd><p>Embeds inputs in learned feature space. Can be called before or after calling <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-meth docutils literal notranslate"><span class="pre">finetune()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – list or array of text to embed.</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np.array of features of shape (n_examples, embedding_size).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.finetune">
<code class="descname">finetune</code><span class="sig-paren">(</span><em>X</em>, <em>Y=None</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.finetune" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>X</strong> – list or array of text.</li>
<li><strong>Y</strong> – integer or string-valued class labels.</li>
<li><strong>batch_size</strong> – integer number of examples per batch. When N_GPUS &gt; 1, this number
corresponds to the number of training examples provided to each GPU.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for finetune.</p>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.generate_text">
<code class="descname">generate_text</code><span class="sig-paren">(</span><em>seed_text=''</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.generate_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a prediction on the Language modeling objective given some seed text. It uses a noisy greedy decoding.
Temperature parameter for decoding is set in the config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length to decode to.</li>
<li><strong>seed_text</strong> – Defaults to the empty string. This will form the starting point to begin modelling</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A string containing the generated text.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="finetune.Classifier.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a saved fine-tuned model from disk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – string path name to load model from.  Same value as previously provided to <a class="reference internal" href="#finetune.Classifier.save" title="finetune.Classifier.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – list or array of text to embed.</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a probability distribution over classes for each example in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – list or array of text to embed.</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of dictionaries.  Each dictionary maps from a class label to its assigned class probability.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of the model to disk in a location with name :param: path. The model is saved in several files
and :param: path is used as a prefix.</p>
<dl class="docutils">
<dt>Save is performed in two steps:</dt>
<dd><ul class="first last simple">
<li>Serialize tf graph to disk using tf.Saver</li>
<li>Serialize python model using pickle</li>
</ul>
</dd>
<dt>Note:</dt>
<dd>Does not serialize state of Adam optimizer.
Should not be used to save / restore a training model.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="finetune.Classifier.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Classifier.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for <cite>featurize</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="finetune.Regressor">
<em class="property">class </em><code class="descclassname">finetune.</code><code class="descname">Regressor</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="finetune.Regressor.featurize">
<code class="descname">featurize</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.featurize" title="Permalink to this definition">¶</a></dt>
<dd><p>Embeds inputs in learned feature space. Can be called before or after calling <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-meth docutils literal notranslate"><span class="pre">finetune()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – list or array of text to embed.</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np.array of features of shape (n_examples, embedding_size).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.finetune">
<code class="descname">finetune</code><span class="sig-paren">(</span><em>X</em>, <em>Y=None</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.finetune" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>X</strong> – list or array of text.</li>
<li><strong>Y</strong> – floating point targets</li>
<li><strong>batch_size</strong> – integer number of examples per batch. When N_GPUS &gt; 1, this number
corresponds to the number of training examples provided to each GPU.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for finetune.</p>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.generate_text">
<code class="descname">generate_text</code><span class="sig-paren">(</span><em>seed_text=''</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.generate_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a prediction on the Language modeling objective given some seed text. It uses a noisy greedy decoding.
Temperature parameter for decoding is set in the config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length to decode to.</li>
<li><strong>seed_text</strong> – Defaults to the empty string. This will form the starting point to begin modelling</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A string containing the generated text.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="finetune.Regressor.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a saved fine-tuned model from disk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – string path name to load model from.  Same value as previously provided to <a class="reference internal" href="#finetune.Regressor.save" title="finetune.Regressor.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – list or array of text to embed.</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a probability distribution over classes for each example in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – list or array of text to embed.</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of dictionaries.  Each dictionary maps from a class label to its assigned class probability.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of the model to disk in a location with name :param: path. The model is saved in several files
and :param: path is used as a prefix.</p>
<dl class="docutils">
<dt>Save is performed in two steps:</dt>
<dd><ul class="first last simple">
<li>Serialize tf graph to disk using tf.Saver</li>
<li>Serialize python model using pickle</li>
</ul>
</dd>
<dt>Note:</dt>
<dd>Does not serialize state of Adam optimizer.
Should not be used to save / restore a training model.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="finetune.Regressor.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Regressor.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for <cite>featurize</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="finetune.MultifieldClassifier">
<em class="property">class </em><code class="descclassname">finetune.</code><code class="descname">MultifieldClassifier</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="finetune.MultifieldClassifier.featurize">
<code class="descname">featurize</code><span class="sig-paren">(</span><em>*Xs</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.featurize" title="Permalink to this definition">¶</a></dt>
<dd><p>Embeds inputs in learned feature space. Can be called before or after calling <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-meth docutils literal notranslate"><span class="pre">finetune()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np.array of features of shape (n_examples, embedding_size).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.finetune">
<code class="descname">finetune</code><span class="sig-paren">(</span><em>*Xs</em>, <em>Y=None</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.finetune" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>Y</strong> – integer or string-valued class labels. It is necessary for the items of Y to be sortable.</li>
<li><strong>batch_size</strong> – integer number of examples per batch. When N_GPUS &gt; 1, this number
corresponds to the number of training examples provided to each GPU.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for finetune.</p>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.generate_text">
<code class="descname">generate_text</code><span class="sig-paren">(</span><em>seed_text=''</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.generate_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a prediction on the Language modeling objective given some seed text. It uses a noisy greedy decoding.
Temperature parameter for decoding is set in the config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length to decode to.</li>
<li><strong>seed_text</strong> – Defaults to the empty string. This will form the starting point to begin modelling</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A string containing the generated text.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="finetune.MultifieldClassifier.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a saved fine-tuned model from disk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – string path name to load model from.  Same value as previously provided to <a class="reference internal" href="#finetune.MultifieldClassifier.save" title="finetune.MultifieldClassifier.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>*Xs</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces X2 list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>*Xs</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces X2 probability distribution over classes for each example in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of dictionaries.  Each dictionary maps from X2 class label to its assigned class probability.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of the model to disk in a location with name :param: path. The model is saved in several files
and :param: path is used as a prefix.</p>
<dl class="docutils">
<dt>Save is performed in two steps:</dt>
<dd><ul class="first last simple">
<li>Serialize tf graph to disk using tf.Saver</li>
<li>Serialize python model using pickle</li>
</ul>
</dd>
<dt>Note:</dt>
<dd>Does not serialize state of Adam optimizer.
Should not be used to save / restore a training model.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldClassifier.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldClassifier.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for <cite>featurize</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="finetune.MultifieldRegressor">
<em class="property">class </em><code class="descclassname">finetune.</code><code class="descname">MultifieldRegressor</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="finetune.MultifieldRegressor.featurize">
<code class="descname">featurize</code><span class="sig-paren">(</span><em>*Xs</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.featurize" title="Permalink to this definition">¶</a></dt>
<dd><p>Embeds inputs in learned feature space. Can be called before or after calling <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-meth docutils literal notranslate"><span class="pre">finetune()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np.array of features of shape (n_examples, embedding_size).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.finetune">
<code class="descname">finetune</code><span class="sig-paren">(</span><em>*Xs</em>, <em>Y=None</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.finetune" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>Y</strong> – floating point targets</li>
<li><strong>batch_size</strong> – integer number of examples per batch. When N_GPUS &gt; 1, this number
corresponds to the number of training examples provided to each GPU.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for finetune.</p>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.generate_text">
<code class="descname">generate_text</code><span class="sig-paren">(</span><em>seed_text=''</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.generate_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a prediction on the Language modeling objective given some seed text. It uses a noisy greedy decoding.
Temperature parameter for decoding is set in the config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length to decode to.</li>
<li><strong>seed_text</strong> – Defaults to the empty string. This will form the starting point to begin modelling</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A string containing the generated text.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="finetune.MultifieldRegressor.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a saved fine-tuned model from disk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – string path name to load model from.  Same value as previously provided to <a class="reference internal" href="#finetune.MultifieldRegressor.save" title="finetune.MultifieldRegressor.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>*Xs</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces X2 list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>*Xs</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces X2 probability distribution over classes for each example in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>*Xs</strong> – <p>lists of text inputs</p>
</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of dictionaries.  Each dictionary maps from X2 class label to its assigned class probability.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of the model to disk in a location with name :param: path. The model is saved in several files
and :param: path is used as a prefix.</p>
<dl class="docutils">
<dt>Save is performed in two steps:</dt>
<dd><ul class="first last simple">
<li>Serialize tf graph to disk using tf.Saver</li>
<li>Serialize python model using pickle</li>
</ul>
</dd>
<dt>Note:</dt>
<dd>Does not serialize state of Adam optimizer.
Should not be used to save / restore a training model.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="finetune.MultifieldRegressor.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.MultifieldRegressor.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for <cite>featurize</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="finetune.SequenceLabeler">
<em class="property">class </em><code class="descclassname">finetune.</code><code class="descname">SequenceLabeler</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="finetune.SequenceLabeler.featurize">
<code class="descname">featurize</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.featurize" title="Permalink to this definition">¶</a></dt>
<dd><p>Embeds inputs in learned feature space. Can be called before or after calling <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-meth docutils literal notranslate"><span class="pre">finetune()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> – An iterable of lists or array of text, shape [batch, n_inputs, tokens]</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np.array of features of shape (n_examples, embedding_size).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.finetune">
<code class="descname">finetune</code><span class="sig-paren">(</span><em>X</em>, <em>Y=None</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.finetune" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>X</strong> – A list of text snippets. Format: [batch_size]</li>
<li><strong>Y</strong> – A list of lists of annotations. Format: [batch_size, n_annotations], where each annotation is of the form:
{‘start’: 0, ‘end’: 5, ‘label’: ‘class’, ‘text’: ‘sample text’}</li>
<li><strong>batch_size</strong> – integer number of examples per batch. When N_GPUS &gt; 1, this number
corresponds to the number of training examples provided to each GPU.</li>
<li><strong>val_size</strong> – Float fraction or int number that represents the size of the validation set.</li>
<li><strong>val_interval</strong> – The interval for which validation is performed, measured in number of steps.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for finetune.</p>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.generate_text">
<code class="descname">generate_text</code><span class="sig-paren">(</span><em>seed_text=''</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.generate_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a prediction on the Language modeling objective given some seed text. It uses a noisy greedy decoding.
Temperature parameter for decoding is set in the config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length to decode to.</li>
<li><strong>seed_text</strong> – Defaults to the empty string. This will form the starting point to begin modelling</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A string containing the generated text.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="finetune.SequenceLabeler.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a saved fine-tuned model from disk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – string path name to load model from.  Same value as previously provided to <a class="reference internal" href="#finetune.SequenceLabeler.save" title="finetune.SequenceLabeler.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – A list / array of text, shape [batch]</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncatindiion.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> – A list / array of text, shape [batch]</li>
<li><strong>max_length</strong> – the number of tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncatindiion.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of the model to disk in a location with name :param: path. The model is saved in several files
and :param: path is used as a prefix.</p>
<dl class="docutils">
<dt>Save is performed in two steps:</dt>
<dd><ul class="first last simple">
<li>Serialize tf graph to disk using tf.Saver</li>
<li>Serialize python model using pickle</li>
</ul>
</dd>
<dt>Note:</dt>
<dd>Does not serialize state of Adam optimizer.
Should not be used to save / restore a training model.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="finetune.SequenceLabeler.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.SequenceLabeler.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for <cite>featurize</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="finetune.Comparison">
<em class="property">class </em><code class="descclassname">finetune.</code><code class="descname">Comparison</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="finetune.Comparison.featurize">
<code class="descname">featurize</code><span class="sig-paren">(</span><em>X1</em>, <em>X2</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.featurize" title="Permalink to this definition">¶</a></dt>
<dd><p>Embeds inputs in learned feature space. Can be called before or after calling <a class="reference internal" href="#module-finetune" title="finetune"><code class="xref py py-meth docutils literal notranslate"><span class="pre">finetune()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X1</strong> – List or array of text, shape [batch]</li>
<li><strong>X2</strong> – List or array of text, shape [batch]</li>
<li><strong>max_length</strong> – the number of byte-pair encoded tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np.array of features of shape (n_examples, embedding_size).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.finetune">
<code class="descname">finetune</code><span class="sig-paren">(</span><em>X1</em>, <em>X2</em>, <em>Y</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.finetune" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>X1</strong> – List or array of text, shape [batch]</li>
<li><strong>X2</strong> – List or array of text, shape [batch]</li>
<li><strong>Y</strong> – integer or string-valued class labels. It is necessary for the items of Y to be sortable.</li>
<li><strong>batch_size</strong> – integer number of examples per batch. When N_GPUS &gt; 1, this number
corresponds to the number of training examples provided to each GPU.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for finetune.</p>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.generate_text">
<code class="descname">generate_text</code><span class="sig-paren">(</span><em>seed_text=''</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.generate_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a prediction on the Language modeling objective given some seed text. It uses a noisy greedy decoding.
Temperature parameter for decoding is set in the config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length to decode to.</li>
<li><strong>seed_text</strong> – Defaults to the empty string. This will form the starting point to begin modelling</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A string containing the generated text.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="finetune.Comparison.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a saved fine-tuned model from disk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> – string path name to load model from.  Same value as previously provided to <a class="reference internal" href="#finetune.Comparison.save" title="finetune.Comparison.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X1</em>, <em>X2</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a list of most likely class labels as determined by the fine-tuned model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X1</strong> – List or array of text, shape [batch]</li>
<li><strong>X2</strong> – List or array of text, shape [batch]</li>
<li><strong>max_length</strong> – the number of byte-pair encoded tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of class labels.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X1</em>, <em>X2</em>, <em>max_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a probability distribution over classes for each example in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X1</strong> – List or array of text, shape [batch]</li>
<li><strong>X2</strong> – List or array of text, shape [batch]</li>
<li><strong>max_length</strong> – the number of byte-pair encoded tokens to be included in the document representation.
Providing more than <cite>max_length</cite> tokens as input will result in truncation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of dictionaries.  Each dictionary maps from a class label to its assigned class probability.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of the model to disk in a location with name :param: path. The model is saved in several files
and :param: path is used as a prefix.</p>
<dl class="docutils">
<dt>Save is performed in two steps:</dt>
<dd><ul class="first last simple">
<li>Serialize tf graph to disk using tf.Saver</li>
<li>Serialize python model using pickle</li>
</ul>
</dd>
<dt>Note:</dt>
<dd>Does not serialize state of Adam optimizer.
Should not be used to save / restore a training model.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="finetune.Comparison.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#finetune.Comparison.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for <cite>featurize</cite>.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Madison May, Ben Townsend.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>